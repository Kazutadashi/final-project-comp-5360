{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs, make_moons, load_iris, load_digits\n",
    "from sklearn.cluster import *\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.metrics import homogeneity_score, homogeneity_completeness_v_measure\n",
    "from sklearn.preprocessing import scale\n",
    "from collections import Counter\n",
    "\n",
    "import hdbscan\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in the data from the pickle objects\n",
    "all_schools = pd.read_pickle(\"allschools_df.pkl\")\n",
    "public_schools = pd.read_pickle(\"public_df.pkl\")\n",
    "for_profit = pd.read_pickle(\"forprofit_df.pkl\")\n",
    "non_profit = pd.read_pickle(\"nonprofit_df.pkl\")\n",
    "\n",
    "allschoolsPCA = pd.read_pickle(\"allschoolsPCA.pkl\")\n",
    "publicPCA = pd.read_pickle(\"publicschoolPCA.pkl\")\n",
    "nonprofitPCA = pd.read_pickle(\"nonprofitPCA.pkl\")\n",
    "forprofitPCA = pd.read_pickle(\"forprofitPCA.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://stackoverflow.com/questions/25633383/how-can-gridsearchcv-be-used-for-clustering-meanshift-or-dbscan\n",
    "\n",
    "def dbscan_grid_search(X_data, lst, clst_count, eps_space = 0.5,\n",
    "                       min_samples_space = 5, min_clust = 0, max_clust = 10):\n",
    "\n",
    "    \"\"\"\n",
    "Performs a hyperparameter grid search for DBSCAN.\n",
    "\n",
    "Parameters:\n",
    "    * X_data            = data used to fit the DBSCAN instance\n",
    "    * lst               = a list to store the results of the grid search\n",
    "    * clst_count        = a list to store the number of non-whitespace clusters\n",
    "    * eps_space         = the range values for the eps parameter\n",
    "    * min_samples_space = the range values for the min_samples parameter\n",
    "    * min_clust         = the minimum number of clusters required after each search iteration in order for a result to be appended to the lst\n",
    "    * max_clust         = the maximum number of clusters required after each search iteration in order for a result to be appended to the lst\n",
    "\n",
    "\"\"\"\n",
    "    # Starting a tally of total iterations\n",
    "    n_iterations = 0\n",
    "\n",
    "    # Looping over each combination of hyperparameters\n",
    "    for eps_val in eps_space:\n",
    "        for samples_val in min_samples_space:\n",
    "\n",
    "            dbscan_grid = DBSCAN(eps = eps_val,\n",
    "                                 min_samples = samples_val)\n",
    "\n",
    "            # fit_transform\n",
    "            clusters = dbscan_grid.fit_predict(X = X_data)\n",
    "\n",
    "            labels = dbscan_grid.labels_\n",
    "\n",
    "            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            n_noise_ = list(labels).count(-1)\n",
    "            \n",
    "\n",
    "            # Counting the amount of data in each cluster\n",
    "            cluster_count = Counter(clusters)\n",
    "\n",
    "            # Saving the number of clusters\n",
    "            n_clusters = sum(abs(pd.np.unique(clusters))) - 1\n",
    "\n",
    "            # Increasing the iteration tally with each run of the loop\n",
    "            n_iterations += 1\n",
    "\n",
    "            # Appending the lst each time n_clusters criteria is reached\n",
    "            if n_clusters >= min_clust and n_clusters <= max_clust:\n",
    "                \n",
    "                lst.append([\"Epsilon: %d\" % eps_val,\n",
    "                                        \"Minimum points: %d\" % samples_val,\n",
    "                                        \"Number of clusters: %d\" % n_clusters_,\n",
    "                                       \"Estimated number of noise points: %d\" % n_noise_,\n",
    "                                       \"Homogeneity: %0.3f\" % metrics.homogeneity_score(X_data[:, 1], labels),\n",
    "                                       \"Completeness: %0.3f\" % metrics.completeness_score(X_data[:, 1], labels),\n",
    "                                       \"V-measure: %0.3f\" % metrics.v_measure_score(X_data[:, 1], labels),\n",
    "                                       \"Adjusted Rand Index: %0.3f\" % metrics.adjusted_rand_score(X_data[:, 1], labels),\n",
    "                                       \"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(X_data[:, 0].reshape(-1,1), labels)])\n",
    "\n",
    "                clst_count.append(cluster_count)\n",
    "\n",
    "    # Printing grid search summary information\n",
    "    print(f\"\"\"Search Complete. \\nYour list is now of length {len(lst)}. \"\"\")\n",
    "    print(f\"\"\"Hyperparameter combinations checked: {n_iterations}. \\n\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering w/ DBSCAN for Principal Components of all school data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setting empty lists in global environment\n",
    "dbscan_clusters = []\n",
    "cluster_count   = []\n",
    "\n",
    "\n",
    "# Inputting function parameters\n",
    "dbscan_grid_search(X_data = allschoolsPCA,\n",
    "                   lst = dbscan_clusters,\n",
    "                   clst_count = cluster_count,\n",
    "                   eps_space = pd.np.arange(0.1, 4, 0.5),\n",
    "                   min_samples_space = pd.np.arange(10, 250, 25),\n",
    "                   min_clust = 2,\n",
    "                   max_clust = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the list of results into pickle objects\n",
    "with open('all_cluster_PCA_list.pkl', 'wb') as f:\n",
    "    pickle.dump(dbscan_clusters, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pickle back in\n",
    "with open('all_cluster_PCA_list.pkl', 'rb') as f:\n",
    "    all_cluster_result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dbscan_model_all = DBSCAN(eps=7, min_samples=20)\n",
    "final_dbscan_model_all.fit(dbscan_X_scaled)\n",
    "y_pred = final_dbscan_model_all.fit_predict(dbscan_X_scaled)\n",
    "\n",
    "dblabels = final_dbscan_model_all.labels_\n",
    "all_n_clusters_ = len(set(dblabels)) - (1 if -1 in dblabels else 0)\n",
    "\n",
    "print(\"Number of clusters: %d\" % all_n_clusters_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(dbscan_X_scaled[:,-5], dbscan_X_scaled[:, -8], c=dblabels,  marker=\"o\", \n",
    "            alpha=0.3, cmap='plasma')\n",
    "\n",
    "plt.xlim(dbscan_X_scaled[:, -5].min()-1, dbscan_X_scaled[:, -5].max()+1)\n",
    "plt.ylim(dbscan_X_scaled[:, -8].min()-1, dbscan_X_scaled[:, -8].max()+1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN with Principal Components of All Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=50, min_samples=25)\n",
    "cluster_labels = clusterer.fit_predict(allschoolsPCA)\n",
    "hdlabels = clusterer.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterList = list(zip(hdlabels, allschoolsPCA.index.values))\n",
    "len(clusterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in sorted(clusterList, key=lambda x: x[0]):\n",
    "    if i[0] < 0:\n",
    "        clusterList.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clusterList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ClusterList = sorted(clusterList, key=lambda x: x[0])\n",
    "#sorted_ClusterList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell creates a rotating 3D plot in a pop up window\n",
    "from matplotlib import interactive\n",
    "interactive(True)\n",
    "%matplotlib qt\n",
    "\n",
    "num_clusters = clusterer.labels_.max()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "color_palette = sns.color_palette('bright', 8)\n",
    "cluster_colors = [color_palette[x] if x >= 0\n",
    "                  else (0.9, 0.9, 0.9)\n",
    "                  for x in clusterer.labels_]\n",
    "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                         zip(cluster_colors, clusterer.probabilities_)]\n",
    "ax.scatter(allschoolsPCA.PC1, allschoolsPCA.PC2, allschoolsPCA.PC3, linewidth=0, \n",
    "                  c=cluster_member_colors, alpha=0.4)\n",
    "\n",
    "\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.title(\"Hierarchical DBSCAN w/ %d Clusters\" % num_clusters)\n",
    "\n",
    "for angle in range(0, 360):\n",
    "    ax.view_init(30, angle)\n",
    "    plt.draw()\n",
    "    plt.pause(.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D scatter plot of top 2 PC's\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "color_palette = sns.color_palette('bright', 8)\n",
    "cluster_colors = [color_palette[x] if x >= 0\n",
    "                  else (0.8, 0.8, 0.8)\n",
    "                  for x in clusterer.labels_]\n",
    "cluster_member_colors = [sns.desaturate(x, p) for x, p in\n",
    "                         zip(cluster_colors, clusterer.probabilities_)]\n",
    "plt.scatter(allschoolsPCA.PC1, allschoolsPCA.PC2,  linewidth=0, c=cluster_member_colors, alpha=0.4)\n",
    "plt.title(\"Hierarchical DBSCAN w/ %d Clusters\" % (num_clusters + 1))\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dendogram of the clusters\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 10))\n",
    "clusterer.condensed_tree_.plot(select_clusters=True,\n",
    "                               selection_palette=sns.color_palette('bright', 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = []\n",
    "cluster2 = []\n",
    "cluster3 = []\n",
    "cluster4 = []\n",
    "cluster5 = []\n",
    "cluster6 = []\n",
    "cluster7 = []\n",
    "cluster8 = []\n",
    "\n",
    "for i in sorted_ClusterList:\n",
    "    if i[0] == 0:\n",
    "        cluster1.append(i)\n",
    "    elif i[0] == 1:\n",
    "        cluster2.append(i)\n",
    "    elif i[0] == 2:\n",
    "        cluster3.append(i)\n",
    "    elif i[0] == 3:\n",
    "        cluster4.append(i)\n",
    "    elif i[0] == 4:\n",
    "        cluster5.append(i)\n",
    "    elif i[0] == 5:\n",
    "        cluster6.append(i)\n",
    "    elif i[0] == 6:\n",
    "        cluster7.append(i)\n",
    "    elif i[0] == 7:\n",
    "        cluster8.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = df2.append(df1[df1['Adj.Factor'] == 0])\n",
    "new = [] \n",
    "\n",
    "for school in cluster1:\n",
    "    if school[1].all(all_schools.index) == True:\n",
    "            new.append(all_schools['CONTROL', 'GRAD_DEBT_MDN_SUPP', 'MD_EARN_WNE_P10'].values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schools.index.any(school[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
