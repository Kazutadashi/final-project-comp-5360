{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from mlxtend.plotting import plot_linear_regression\n",
    "from sklearn.decomposition import PCA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csc_df = pd.DataFrame(pd.read_csv(\"data_files/Most-Recent-Cohorts-Scorecard-Elements.csv\"))\n",
    "# Removing irrelevant features\n",
    "csc_df = csc_df.drop(csc_df.columns[[0,1,2,6,7]], axis=1)\n",
    "csc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing schools not in current operation\n",
    "csc_df = csc_df.drop(csc_df[csc_df['CURROPER'] == 0].index)\n",
    "print(csc_df.shape)\n",
    "\n",
    "# Replacing PrivacySuppressed with NaN\n",
    "csc_df = csc_df.replace('PrivacySuppressed', np.nan)\n",
    "print(csc_df.shape)\n",
    "\n",
    "\n",
    "# For clustering\n",
    "numeric_school_data = csc_df.iloc[:,3:]\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# This next section will impute the data, and verify the integrity of the data.\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# Resolving any NaN values using Imputation\n",
    "# Credit to O.rka at https://stackoverflow.com/questions/33660836/impute-entire-dataframe-all-columns-using-scikit-learn-sklearn-without-itera\n",
    "fill_NaN = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputed_df = pd.DataFrame(fill_NaN.fit_transform(numeric_school_data))\n",
    "imputed_df.columns = numeric_school_data.columns\n",
    "imputed_df.index = list(csc_df.iloc[:,0])\n",
    "\n",
    "# Check for incorrect column types\n",
    "for i in range(len(imputed_df.dtypes)):\n",
    "    if imputed_df.dtypes[i] != imputed_df.dtypes[1]:\n",
    "        print(imputed_df.dtypes[i])\n",
    "\n",
    "print(\"No other bad dtypes.\")\n",
    "\n",
    "# Check for NaN values\n",
    "imputed_df.isnull().values.any()\n",
    "\n",
    "print(\"No other NaN values.\")\n",
    "\n",
    "print(np.where(np.isnan(imputed_df)))\n",
    "\n",
    "for i in range(len(imputed_df.columns)):\n",
    "    for j in range(len(imputed_df.index)):\n",
    "        if np.isfinite(imputed_df.iloc[j,i]) == False:\n",
    "            print(j,i)\n",
    "            print(imputed_df.iloc[j,i])\n",
    "\n",
    "print(\"No other non-finite values.\")\n",
    "\n",
    "\n",
    "#imputed_df[imputed_df['INSTNM'] == 'University of Utah']\n",
    "\n",
    "print(\"All Schools:\", imputed_df.shape)\n",
    "\n",
    "# Splitting into main groups\n",
    "public_schools_df = imputed_df[imputed_df['CONTROL'] == 1]\n",
    "print(\"Public Schools:\", public_schools_df.shape)\n",
    "private2_schools_df = imputed_df[imputed_df['CONTROL'] == 2]\n",
    "print(\"Private NP Schools:\", private2_schools_df.shape)\n",
    "private3_schools_df = imputed_df[imputed_df['CONTROL'] == 3]\n",
    "print(\"Private FP Schools:\", private3_schools_df.shape)\n",
    "\n",
    "#put dataframes into pickle objects\n",
    "imputed_df.to_pickle(\"allschools_df.pkl\")\n",
    "public_schools_df.to_pickle(\"public_df.pkl\")\n",
    "private2_schools_df.to_pickle(\"nonprofit_df.pkl\")\n",
    "private3_schools_df.to_pickle(\"forprofit_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for All Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X = preprocessing.normalize(imputed_df)\n",
    "pca_model = PCA()\n",
    "snsd_PCA = pca_model.fit_transform(normalized_X)\n",
    "\n",
    "print(\"The first 3 components explain \",end=\"\")\n",
    "print(round((pca_model.explained_variance_ratio_[0]+\n",
    "       pca_model.explained_variance_ratio_[1]+\n",
    "       pca_model.explained_variance_ratio_[2]),4)*100,\n",
    "       \"%\",sep=\"\",end=\"\")\n",
    "print(\" of the variance in this data.\")\n",
    "\n",
    "# Plotting the explained variance for each principle component\n",
    "list_of_PCA_variances = []\n",
    "for i in range(len(pca_model.explained_variance_ratio_)):\n",
    "    list_of_PCA_variances.append(pca_model.explained_variance_ratio_[i])\n",
    "    \n",
    "print(\"\\nThese are the principle components that explain more tha 0.1% of variance\")\n",
    "components_to_use = []\n",
    "for variance in list_of_PCA_variances:\n",
    "    if variance > 0.001:\n",
    "        components_to_use.append(variance)\n",
    "print(components_to_use)\n",
    "\n",
    "# This shows an extreme drop off for variances, which infers that we do not need a majority of these columns\n",
    "# for clustering\n",
    "plt.plot(np.linspace(1, len(pca_model.explained_variance_ratio_), 116), list_of_PCA_variances)\n",
    "plt.show()\n",
    "plt.plot(list(range(len(components_to_use))), components_to_use, '-o')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.xticks(list(range(len(components_to_use))))\n",
    "plt.show()\n",
    "plt.scatter(snsd_PCA[:,0],snsd_PCA[:,1])\n",
    "plt.show()\n",
    "\n",
    "PCA_DF = pd.DataFrame(snsd_PCA[:,0:7], columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7'], \n",
    "                      index=list(csc_df.iloc[:,0]))\n",
    "\n",
    "#all schools PCA into pickle object\n",
    "\n",
    "PCA_DF.to_pickle(\"allschoolsPCA.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for Public Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X_pub = preprocessing.normalize(public_schools_df)\n",
    "pca_pub_model = PCA()\n",
    "pub_PCA = pca_pub_model.fit_transform(normalized_X_pub)\n",
    "\n",
    "print(\"The first 3 components explain \",end=\"\")\n",
    "print(round((pca_pub_model.explained_variance_ratio_[0]+\n",
    "       pca_pub_model.explained_variance_ratio_[1]+\n",
    "       pca_pub_model.explained_variance_ratio_[2]),5)*100,\n",
    "       \"%\",sep=\"\",end=\"\")\n",
    "print(\" of the variance in the data for public schools.\")\n",
    "\n",
    "# Plotting the explained variance for each principle component\n",
    "list_pub_PCA_variances = []\n",
    "for i in range(len(pca_pub_model.explained_variance_ratio_)):\n",
    "    list_pub_PCA_variances.append(pca_pub_model.explained_variance_ratio_[i])\n",
    "    \n",
    "print(\"\\nThese are the principle components that explain more tha 0.1% of variance in public school data\")\n",
    "components_to_use_pub = []\n",
    "for variance in list_pub_PCA_variances:\n",
    "    if variance > 0.001:\n",
    "        components_to_use_pub.append(variance)\n",
    "print(components_to_use_pub)\n",
    "\n",
    "# This shows an extreme drop off for variances, which infers that we do not need a majority of these columns\n",
    "# for clustering\n",
    "plt.plot(np.linspace(1, len(pca_pub_model.explained_variance_ratio_), 116), list_pub_PCA_variances)\n",
    "plt.show()\n",
    "plt.plot(list(range(len(components_to_use_pub))), components_to_use_pub, '-o')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.xticks(list(range(len(components_to_use_pub))))\n",
    "plt.show()\n",
    "plt.scatter(pub_PCA[:,0],pub_PCA[:,1])\n",
    "plt.show()\n",
    "\n",
    "pub_pca_df = pd.DataFrame(pub_PCA[:,0:7], columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7'], \n",
    "                      index=list(public_schools_df.iloc[:,0]))\n",
    "\n",
    "#PCA into pickle object\n",
    "\n",
    "pub_pca_df.to_pickle(\"publicschoolPCA.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for Non-Profit Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X_np = preprocessing.normalize(private2_schools_df)\n",
    "pca_np_model = PCA()\n",
    "np_PCA = pca_np_model.fit_transform(normalized_X_np)\n",
    "\n",
    "print(\"The first 3 components explain \",end=\"\")\n",
    "print(round((pca_np_model.explained_variance_ratio_[0]+\n",
    "       pca_np_model.explained_variance_ratio_[1]+\n",
    "       pca_np_model.explained_variance_ratio_[2]),4)*100,\n",
    "       \"%\",sep=\"\",end=\"\")\n",
    "print(\" of the variance in the data for Private Non-Profit schools.\")\n",
    "\n",
    "# Plotting the explained variance for each principle component\n",
    "list_np_PCA_variances = []\n",
    "for i in range(len(pca_np_model.explained_variance_ratio_)):\n",
    "    list_np_PCA_variances.append(pca_np_model.explained_variance_ratio_[i])\n",
    "    \n",
    "print(\"\\nThese are the principle components that explain more tha 0.1% of variance in non-profit school data\")\n",
    "components_to_use_np = []\n",
    "for variance in list_np_PCA_variances:\n",
    "    if variance > 0.001:\n",
    "        components_to_use_np.append(variance)\n",
    "print(components_to_use_np)\n",
    "\n",
    "# This shows an extreme drop off for variances, which infers that we do not need a majority of these columns\n",
    "# for clustering\n",
    "plt.plot(np.linspace(1, len(pca_np_model.explained_variance_ratio_), 116), list_np_PCA_variances)\n",
    "plt.show()\n",
    "plt.plot(list(range(len(components_to_use_np))), components_to_use_np, '-o')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.xticks(list(range(len(components_to_use_np))))\n",
    "plt.show()\n",
    "plt.scatter(np_PCA[:,0],np_PCA[:,1])\n",
    "plt.show()\n",
    "\n",
    "np_pca_df = pd.DataFrame(np_PCA[:,0:7], columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7'], \n",
    "                      index=list(private2_schools_df.iloc[:,0]))\n",
    "\n",
    "#PCA into pickle object\n",
    "\n",
    "np_pca_df.to_pickle(\"nonprofitPCA.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA for For-Profit Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_X_fp = preprocessing.normalize(private3_schools_df)\n",
    "pca_fp_model = PCA()\n",
    "fp_PCA = pca_fp_model.fit_transform(normalized_X_fp)\n",
    "\n",
    "print(\"The first 3 components explain \",end=\"\")\n",
    "print(round((pca_fp_model.explained_variance_ratio_[0]+\n",
    "       pca_fp_model.explained_variance_ratio_[1]+\n",
    "       pca_fp_model.explained_variance_ratio_[2]),4)*100,\n",
    "       \"%\",sep=\"\",end=\"\")\n",
    "print(\" of the variance in the data for Private For-Profit schools.\")\n",
    "\n",
    "# Plotting the explained variance for each principle component\n",
    "list_fp_PCA_variances = []\n",
    "for i in range(len(pca_fp_model.explained_variance_ratio_)):\n",
    "    list_fp_PCA_variances.append(pca_fp_model.explained_variance_ratio_[i])\n",
    "    \n",
    "print(\"\\nThese are the principle components that explain more tha 0.1% of variance in non-profit school data\")\n",
    "components_to_use_fp = []\n",
    "for variance in list_fp_PCA_variances:\n",
    "    if variance > 0.001:\n",
    "        components_to_use_fp.append(variance)\n",
    "print(components_to_use_fp)\n",
    "\n",
    "# This shows an extreme drop off for variances, which infers that we do not need a majority of these columns\n",
    "# for clustering\n",
    "plt.plot(np.linspace(1, len(pca_fp_model.explained_variance_ratio_), 116), list_fp_PCA_variances)\n",
    "plt.show()\n",
    "plt.plot(list(range(len(components_to_use_fp))), components_to_use_fp, '-o')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.xticks(list(range(len(components_to_use_fp))))\n",
    "plt.show()\n",
    "plt.scatter(fp_PCA[:,0], fp_PCA[:,1])\n",
    "plt.show()\n",
    "\n",
    "fp_pca_df = pd.DataFrame(fp_PCA[:,0:7], columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7'], \n",
    "                      index=list(private3_schools_df.iloc[:,0]))\n",
    "\n",
    "#PCA into pickle object\n",
    "\n",
    "fp_pca_df.to_pickle(\"forprofitPCA.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median Debt from all schools:\", round(imputed_df.GRAD_DEBT_MDN_SUPP.mean(),2))\n",
    "print(\"Median Earnings 10 years after entry (All schools):\", round(imputed_df.MD_EARN_WNE_P10.mean(),2))\n",
    "\n",
    "print(\"Median Public School Loan Debt:\", round(public_schools_df.GRAD_DEBT_MDN_SUPP.mean(),2))\n",
    "print(\"Median Earnings 10 years after entry (public school):\", round(public_schools_df.MD_EARN_WNE_P10.mean(),2))\n",
    "\n",
    "print(\"Median Private Nonprofit School Loan Debt:\", round(private2_schools_df.GRAD_DEBT_MDN_SUPP.mean(),2))\n",
    "print(\"Median Earnings 10 years after entry (private NP school):\", \n",
    "      round(private2_schools_df.MD_EARN_WNE_P10.mean(),2))\n",
    "\n",
    "print(\"Median Private For-Profit School Loan Debt:\", round(private3_schools_df.GRAD_DEBT_MDN_SUPP.mean(),2))\n",
    "print(\"Median Earnings 10 years after entry (private FP school):\", \n",
    "      round(private3_schools_df.MD_EARN_WNE_P10.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubdebt = public_schools_df.GRAD_DEBT_MDN_SUPP\n",
    "pubearn = public_schools_df.MD_EARN_WNE_P10\n",
    "npdebt = private2_schools_df.GRAD_DEBT_MDN_SUPP\n",
    "npearn = private2_schools_df.MD_EARN_WNE_P10\n",
    "fpdebt = private3_schools_df.GRAD_DEBT_MDN_SUPP\n",
    "fpearn = private3_schools_df.MD_EARN_WNE_P10\n",
    "\n",
    "# create a linear regression object\n",
    "publr = sm.ols(formula=\"MD_EARN_WNE_P10 ~ GRAD_DEBT_MDN_SUPP\", data=public_schools_df, missing='drop').fit()\n",
    "nplr = sm.ols(formula=\"MD_EARN_WNE_P10 ~ GRAD_DEBT_MDN_SUPP\", data=private2_schools_df, missing='drop').fit()\n",
    "fplr = sm.ols(formula=\"MD_EARN_WNE_P10 ~ GRAD_DEBT_MDN_SUPP\", data=private3_schools_df, missing='drop').fit()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "ax1.scatter(pubdebt, pubearn, s=8, c='b', marker=\"s\", label='Public School')\n",
    "ax1.plot(pubdebt, publr.predict(), c='b', linewidth=2)\n",
    "ax1.scatter(npdebt, npearn, s=8, c='r', marker=\"o\", label='Nonprofit Private')\n",
    "ax1.plot(npdebt, nplr.predict(), c='r', linewidth=2)\n",
    "ax1.scatter(fpdebt, fpearn, s=8, c='y', marker=\"x\", label='For-Profit Private')\n",
    "ax1.plot(fpdebt, fplr.predict(), c='y', linewidth=2)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Median Debt ($)')\n",
    "plt.ylabel('Median Earning 10 years after Entry($)')\n",
    "plt.title('Debt vs. Earnings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
